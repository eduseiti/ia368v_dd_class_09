{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduseiti/ia368v_dd_class_09/blob/main/DL_reranking_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfQ6E6J0g82D"
      },
      "source": [
        "# TREC-COVID DL reranking evaluation\n",
        "\n",
        "This notebook perform reranking tests over TREC COVID queries BM25 results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk1G-QQkbutO"
      },
      "source": [
        "## Prepare the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xONe_AODg82H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YOYQA_iXg82J"
      },
      "outputs": [],
      "source": [
        "IN_COLAB='google.colab' in sys.modules\n",
        "LINK_WITH_COMET=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLrS2Cwhg82J",
        "outputId": "b7752003-374b-4ba1-ec41-677cb16fac5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for nmslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "\n",
        "    WORKING_FOLDER=\"/content/drive/MyDrive/unicamp/ia368v_dd/aula_09\"\n",
        "\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    os.chdir(WORKING_FOLDER)\n",
        "\n",
        "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "    \n",
        "\n",
        "\n",
        "    !pip install pyserini -q\n",
        "    !pip install faiss-cpu -q\n",
        "\n",
        "    # !apt-get install maven -qq\n",
        "    # !git clone --recurse-submodules https://github.com/castorini/pyserini.git\n",
        "    # !cd pyserini\n",
        "    # !cd tools/eval && tar xvfz trec_eval.9.0.4.tar.gz && cd trec_eval.9.0.4 && make && cd ../../..\n",
        "    # !cd tools/eval/ndeval && make && cd ../../..\n",
        "\n",
        "    PYSERINI_FOLDER=\"/content/drive/MyDrive/unicamp/ia368v_dd/pyserini/\"\n",
        "\n",
        "    TREC_EVAL_FULLPATH=PYSERINI_FOLDER+\"tools/eval/trec_eval.9.0.4/trec_eval\"\n",
        "    PYSERINI_TOOLS_FOLDER=PYSERINI_FOLDER+\"tools/scripts/msmarco/\"\n",
        "\n",
        "    !pip install transformers -q\n",
        "\n",
        "    # !git clone --recurse-submodules https://github.com/castorini/anserini.git\n",
        "    # !cd anserini\n",
        "    # !mvn clean package appassembler:assemble\n",
        "\n",
        "    os.environ[\"ANSERINI_CLASSPATH\"]=\"content/drive/MyDrive/unicamp/ia368v_dd/aula_09/pyserini/anserini/target\"\n",
        "\n",
        "    !chmod +x /content/drive/MyDrive/unicamp/ia368v_dd/pyserini/tools/eval/trec_eval.9.0.4/trec_eval\n",
        "\n",
        "    PYSERINI_PREVIOUS_RUN=\"run.trec_covid_original_complete_20230503_135137.txt\"\n",
        "else:\n",
        "    WORKING_FOLDER=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/ia368v_dd_class_09/\"\n",
        "    PYSERINI_FOLDER=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/pyserini/\"\n",
        "    \n",
        "    TREC_EVAL_FULLPATH=PYSERINI_FOLDER+\"tools/eval/trec_eval.9.0.4/trec_eval\"\n",
        "    \n",
        "    os.environ[\"ANSERINI_CLASSPATH\"]=\"/media/eduseiti/bigdata01/unicamp/ia368v_dd/anserini/target\"\n",
        "\n",
        "    PYSERINI_PREVIOUS_RUN=\"run.trec_covid_original_complete_20230501_141634.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YIfTjyXSg82K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "import json\n",
        "\n",
        "import time\n",
        "\n",
        "import re\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AJJGWR1Ug82K"
      },
      "outputs": [],
      "source": [
        "TREC_COVID_MERGED_FILE=\"trec_covid_merged_data.tsv\"\n",
        "TREC_COVID_DOCUMENTS_FILE=\"trec_covid_original_title_text_merged.tsv\"\n",
        "\n",
        "TREC_COVID_QUERIES=\"trec_covid_queries.tsv\"\n",
        "TREC_COVID_QRELS=\"trec_covid_qrels.tsv\"\n",
        "\n",
        "API_KEYS_FILE=\"../api_keys_20230324.json\"\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AfFxGKmGg82L"
      },
      "outputs": [],
      "source": [
        "TREC_COVID_ORIGINAL_TITLE_TEXT_MERGED_FILENAME=\"trec_covid_original_title_text_merged.tsv\"\n",
        "TREC_COVID_ORIGINAL_FOLDER=\"trec_covid_original\"\n",
        "TREC_COVID_ORIGINAL_INDEX_FOLDER=\"trec_covid_original/index\"\n",
        "TREC_COVID_ORIGINAL_RUNS_FOLDER=\"trec_covid_original/runs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QkLxXX1qg82L"
      },
      "outputs": [],
      "source": [
        "TREC_COVID_RERANKING_RUNS_FOLDER=\"trec_covid_reranking_runs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f7iQFL1_wmj0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup, get_constant_schedule\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils import data\n",
        "from transformers import BatchEncoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmM0p0QKg82M"
      },
      "source": [
        "## Set the random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OmpjeMmrg82N"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 6\n",
        "\n",
        "rng = np.random.default_rng(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwc7WAu_g82N"
      },
      "source": [
        "### Initialize reranking model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-N4QG5B_g82O"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME='microsoft/MiniLM-L12-H384-uncased'\n",
        "MS_MARCO_PRETRAINED_MODEL=\"pretrain_20230315_180741\"\n",
        "\n",
        "MAX_TOKENS_LENGTH=512\n",
        "\n",
        "RETURN_OVERFLOWING_TOKENS=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nXt_hVWgg82O"
      },
      "outputs": [],
      "source": [
        "TRAIN_OUTPUT_FOLDER=\"trained_models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PyaEzBQcg82O"
      },
      "outputs": [],
      "source": [
        "if RETURN_OVERFLOWING_TOKENS:\n",
        "    TREC_COVID_TOKENIZED_BM25_RUN=\"trec_covid_tokenized_{}.pkl\"\n",
        "else:\n",
        "    TREC_COVID_TOKENIZED_BM25_RUN=\"trec_covid_tokenized_no_overflow_{}.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wmLP617Ag82O"
      },
      "outputs": [],
      "source": [
        "PYSERINI_TEST_RUN_RERANKED_FILENAME_FORMAT=\"run.trec_covid_reranking_{}_{}_{}.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5Qat_vZCg82P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "c468a65e073244cc861799705b738b16",
            "f971d8cc79904430b5c66af40416d730",
            "f4065226ff5f4447928b676724fd8f00",
            "1c356f48b5164fde9df0e892791cd3db",
            "afc6022e473b43e19d51e44fc618024d",
            "2d269b3cd8a042269b470857405eecb5",
            "66e5e3db36424a4b8a6039e36620a821",
            "1d98f568966a4f439fef4caf300032e4",
            "b0781deb296049e4b7424ba58588aaff",
            "918dede8c50d47efb14f42a566447c6b",
            "831cc349c4524ec4bbc302a9d1682f7e",
            "18dc59cbf3cb4407bfd14159638ccc70",
            "18333806ded246a3beb097e0701d0224",
            "a76e07c18b0647e3a625b51394abe59e",
            "af89b666792d426da404704803383594",
            "3ab2bbdf551b46169ef2a7d5cd818b9b",
            "f3a723b2eef44ddcb2e4317b34d19336",
            "5422775c30124537a21a613c7fd60364",
            "163f031c2ba8488db6b70db259da5c29",
            "f77238a397804c828c8473a7e0b8b46a",
            "167ef29b30a84542864ba37251d0f689",
            "b8b6d16af6c44a8c9f3f6345b4e85695",
            "b61a6bee533c4ddc9c9e386a7425585b",
            "e2502364ea1244a6a8866c183bc7053b",
            "81a1bce6781d42c2b7ed8265b0c4199e",
            "24fb48ae14f947f1ab15ff03fccc86ab",
            "39b0405462a442b18d72ae0fd3e43398",
            "5afa3904a1404c99b93e380f2d3e515b",
            "c077363154164a89aa54a553b3d884a1",
            "85cbb9c7592549eebe2bb52842deb786",
            "e472dfab037d43fdb4b6e7765de7d554",
            "d8c42e43f2334e4c918f8980fd43e27c",
            "e434a96a95434b7cbbf870957e4c6a74",
            "95ac93a527e84d4b88d476d43824dacd",
            "f3b6ce71d1cb4ec6bf5f0c524b60fbdf",
            "3c8dcd786f2043f3baf766bbf19cafd4",
            "733ed6a24f8044e8ac0881dd9e958773",
            "73e2b8fb0b104319a33d00afdedfa000",
            "03ff3b2ca66a44518306ebeb3512d8e4",
            "a2920381faad47aaae0b9b22275cf0ef",
            "6853397bce8b4682976ef1223a6eef87",
            "a2f0cd8f60954acba9f67552598cf5d2",
            "270ea75316e24292a7e705f199d53749",
            "d9938702085a45898b9b23dc5a45a39b"
          ]
        },
        "outputId": "024b1b04-0ea4-4090-88dc-db1b739e6ac0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c468a65e073244cc861799705b738b16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18dc59cbf3cb4407bfd14159638ccc70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b61a6bee533c4ddc9c9e386a7425585b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95ac93a527e84d4b88d476d43824dacd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DcXd955oJhRE"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iet6vPCwJhRE",
        "outputId": "d45aaae9-c1c0-4bf0-e3bd-f3c188878f0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(os.path.join(TREC_COVID_ORIGINAL_RUNS_FOLDER, PYSERINI_PREVIOUS_RUN)):\n",
        "    pyserini_runfile = PYSERINI_PREVIOUS_RUN\n",
        "\n",
        "    run_ready=True\n",
        "else:\n",
        "    run_ready=False\n",
        "\n",
        "    print(\"Need to execute Pyserini run...\")"
      ],
      "metadata": {
        "id": "KlLPvnWJqa5s"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95af9627"
      },
      "source": [
        "### Convert TREC COVID to Pyserini's format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "e6d8accb"
      },
      "outputs": [],
      "source": [
        "if not run_ready:\n",
        "    !python3 ./pyserini/tools/scripts/msmarco/convert_collection_to_jsonl.py \\\n",
        "        --collection-path {TREC_COVID_ORIGINAL_TITLE_TEXT_MERGED_FILENAME} \\\n",
        "        --output-folder {TREC_COVID_ORIGINAL_FOLDER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21319cd6"
      },
      "source": [
        "### Create a Pyserini BM25 index for the entire TREC COVID dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "d7f2ade0"
      },
      "outputs": [],
      "source": [
        "if not run_ready:\n",
        "    os.chdir(PYSERINI_FOLDER)\n",
        "\n",
        "    !python3 -m pyserini.index.lucene \\\n",
        "        --collection JsonCollection \\\n",
        "        --input {WORKING_FOLDER}/{TREC_COVID_ORIGINAL_FOLDER} \\\n",
        "        --index {WORKING_FOLDER}/{TREC_COVID_ORIGINAL_INDEX_FOLDER} \\\n",
        "        --generator DefaultLuceneDocumentGenerator \\\n",
        "        --threads 9 \\\n",
        "        --storePositions --storeDocvectors --storeRaw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnEsrk9yg82Q"
      },
      "source": [
        "## Perform BM25 search over TREC-COVID queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BXMd9Ning82R"
      },
      "outputs": [],
      "source": [
        "if not run_ready:\n",
        "    execution_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    pyserini_runfile = \"run.trec_covid_original_complete_{}.txt\".format(execution_timestamp)\n",
        "\n",
        "    !python3 -m pyserini.search.lucene \\\n",
        "        --index {WORKING_FOLDER}/{TREC_COVID_ORIGINAL_INDEX_FOLDER} \\\n",
        "        --topics {WORKING_FOLDER}/{TREC_COVID_QUERIES} \\\n",
        "        --output {WORKING_FOLDER}/{TREC_COVID_ORIGINAL_RUNS_FOLDER}/{pyserini_runfile} \\\n",
        "        --output-format trec \\\n",
        "        --hits 1000 \\\n",
        "        --bm25 --k1 0.82 --b 0.68 \\\n",
        "        --threads 8\n",
        "\n",
        "    os.chdir(WORKING_FOLDER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WyH4qV7g82R"
      },
      "source": [
        "## Now prepare the BM25 results for reranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hcUx0Rjg82R"
      },
      "source": [
        "### Load the TREC COVID documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "H0VQmE1Cg82R",
        "outputId": "12024ed6-3681-4cef-f751-b673b662eb50"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  corpus-id  \\\n",
              "0  ug7v899j   \n",
              "1  02tnwd4m   \n",
              "2  ejv2xln0   \n",
              "3  2b73a28n   \n",
              "4  9785vg6d   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         corpus-title-text  \n",
              "0  Clinical features of culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi ArabiaOBJECTIVE: This retrospective chart review describes the epidemiology and clinical features of 40 patients with culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia. METHODS: Patients with positive M. pneumoniae cultures from respiratory specimens from January 1997 through December 1998 were identified through the Microbiology records. Charts of patients were reviewed. RESULTS: 40 patients were identified, 33 (82.5%) of whom required admission. Most infections (92.5%) were community-acquired. The infection affected all age groups but was most common in infants (32.5%) and pre-school children (22.5%). It occurred year-round but was most common in the fall (35%) and spring (30%). More than three-quarters of patients (77.5%) had comorbidities. Twenty-four isolates (60%) were associated with pneumonia, 14 (35%) with upper respiratory tract infections, and 2 (5%) with bronchiolitis. Cough (82.5%), fever (75%), and malaise (58.8%) were the most common symptoms, and crepitations (60%), and wheezes (40%) were the most common signs. Most patients with pneumonia had crepitations (79.2%) but only 25% had bronchial breathing. Immunocompromised patients were more likely than non-immunocompromised patients to present with pneumonia (8/9 versus 16/31, P = 0.05). Of the 24 patients with pneumonia, 14 (58.3%) had uneventful recovery, 4 (16.7%) recovered following some complications, 3 (12.5%) died because of M pneumoniae infection, and 3 (12.5%) died due to underlying comorbidities. The 3 patients who died of M pneumoniae pneumonia had other comorbidities. CONCLUSION: our results were similar to published data except for the finding that infections were more common in infants and preschool children and that the mortality rate of pneumonia in patients with comorbidities was high.  \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Nitric oxide: a pro-inflammatory mediator in lung disease?Inflammatory diseases of the respiratory tract are commonly associated with elevated production of nitric oxide (NO•) and increased indices of NO• -dependent oxidative stress. Although NO• is known to have anti-microbial, anti-inflammatory and anti-oxidant properties, various lines of evidence support the contribution of NO• to lung injury in several disease models. On the basis of biochemical evidence, it is often presumed that such NO• -dependent oxidations are due to the formation of the oxidant peroxynitrite, although alternative mechanisms involving the phagocyte-derived heme proteins myeloperoxidase and eosinophil peroxidase might be operative during conditions of inflammation. Because of the overwhelming literature on NO• generation and activities in the respiratory tract, it would be beyond the scope of this commentary to review this area comprehensively. Instead, it focuses on recent evidence and concepts of the presumed contribution of NO• to inflammatory diseases of the lung.  \n",
              "2                                                                                                                                                                                                                                                                                           Surfactant protein-D and pulmonary host defenseSurfactant protein-D (SP-D) participates in the innate response to inhaled microorganisms and organic antigens, and contributes to immune and inflammatory regulation within the lung. SP-D is synthesized and secreted by alveolar and bronchiolar epithelial cells, but is also expressed by epithelial cells lining various exocrine ducts and the mucosa of the gastrointestinal and genitourinary tracts. SP-D, a collagenous calcium-dependent lectin (or collectin), binds to surface glycoconjugates expressed by a wide variety of microorganisms, and to oligosaccharides associated with the surface of various complex organic antigens. SP-D also specifically interacts with glycoconjugates and other molecules expressed on the surface of macrophages, neutrophils, and lymphocytes. In addition, SP-D binds to specific surfactant-associated lipids and can influence the organization of lipid mixtures containing phosphatidylinositol in vitro. Consistent with these diverse in vitro activities is the observation that SP-D-deficient transgenic mice show abnormal accumulations of surfactant lipids, and respond abnormally to challenge with respiratory viruses and bacterial lipopolysaccharides. The phenotype of macrophages isolated from the lungs of SP-D-deficient mice is altered, and there is circumstantial evidence that abnormal oxidant metabolism and/or increased metalloproteinase expression contributes to the development of emphysema. The expression of SP-D is increased in response to many forms of lung injury, and deficient accumulation of appropriately oligomerized SP-D might contribute to the pathogenesis of a variety of human lung diseases.  \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Role of endothelin-1 in lung diseaseEndothelin-1 (ET-1) is a 21 amino acid peptide with diverse biological activity that has been implicated in numerous diseases. ET-1 is a potent mitogen regulator of smooth muscle tone, and inflammatory mediator that may play a key role in diseases of the airways, pulmonary circulation, and inflammatory lung diseases, both acute and chronic. This review will focus on the biology of ET-1 and its role in lung disease.  \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Gene expression in epithelial cells in response to pneumovirus infectionRespiratory syncytial virus (RSV) and pneumonia virus of mice (PVM) are viruses of the family Paramyxoviridae, subfamily pneumovirus, which cause clinically important respiratory infections in humans and rodents, respectively. The respiratory epithelial target cells respond to viral infection with specific alterations in gene expression, including production of chemoattractant cytokines, adhesion molecules, elements that are related to the apoptosis response, and others that remain incompletely understood. Here we review our current understanding of these mucosal responses and discuss several genomic approaches, including differential display reverse transcription-polymerase chain reaction (PCR) and gene array strategies, that will permit us to unravel the nature of these responses in a more complete and systematic manner.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2652324f-ea57-44a7-8cb4-b1a067079969\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>corpus-id</th>\n",
              "      <th>corpus-title-text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ug7v899j</td>\n",
              "      <td>Clinical features of culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi ArabiaOBJECTIVE: This retrospective chart review describes the epidemiology and clinical features of 40 patients with culture-proven Mycoplasma pneumoniae infections at King Abdulaziz University Hospital, Jeddah, Saudi Arabia. METHODS: Patients with positive M. pneumoniae cultures from respiratory specimens from January 1997 through December 1998 were identified through the Microbiology records. Charts of patients were reviewed. RESULTS: 40 patients were identified, 33 (82.5%) of whom required admission. Most infections (92.5%) were community-acquired. The infection affected all age groups but was most common in infants (32.5%) and pre-school children (22.5%). It occurred year-round but was most common in the fall (35%) and spring (30%). More than three-quarters of patients (77.5%) had comorbidities. Twenty-four isolates (60%) were associated with pneumonia, 14 (35%) with upper respiratory tract infections, and 2 (5%) with bronchiolitis. Cough (82.5%), fever (75%), and malaise (58.8%) were the most common symptoms, and crepitations (60%), and wheezes (40%) were the most common signs. Most patients with pneumonia had crepitations (79.2%) but only 25% had bronchial breathing. Immunocompromised patients were more likely than non-immunocompromised patients to present with pneumonia (8/9 versus 16/31, P = 0.05). Of the 24 patients with pneumonia, 14 (58.3%) had uneventful recovery, 4 (16.7%) recovered following some complications, 3 (12.5%) died because of M pneumoniae infection, and 3 (12.5%) died due to underlying comorbidities. The 3 patients who died of M pneumoniae pneumonia had other comorbidities. CONCLUSION: our results were similar to published data except for the finding that infections were more common in infants and preschool children and that the mortality rate of pneumonia in patients with comorbidities was high.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02tnwd4m</td>\n",
              "      <td>Nitric oxide: a pro-inflammatory mediator in lung disease?Inflammatory diseases of the respiratory tract are commonly associated with elevated production of nitric oxide (NO•) and increased indices of NO• -dependent oxidative stress. Although NO• is known to have anti-microbial, anti-inflammatory and anti-oxidant properties, various lines of evidence support the contribution of NO• to lung injury in several disease models. On the basis of biochemical evidence, it is often presumed that such NO• -dependent oxidations are due to the formation of the oxidant peroxynitrite, although alternative mechanisms involving the phagocyte-derived heme proteins myeloperoxidase and eosinophil peroxidase might be operative during conditions of inflammation. Because of the overwhelming literature on NO• generation and activities in the respiratory tract, it would be beyond the scope of this commentary to review this area comprehensively. Instead, it focuses on recent evidence and concepts of the presumed contribution of NO• to inflammatory diseases of the lung.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ejv2xln0</td>\n",
              "      <td>Surfactant protein-D and pulmonary host defenseSurfactant protein-D (SP-D) participates in the innate response to inhaled microorganisms and organic antigens, and contributes to immune and inflammatory regulation within the lung. SP-D is synthesized and secreted by alveolar and bronchiolar epithelial cells, but is also expressed by epithelial cells lining various exocrine ducts and the mucosa of the gastrointestinal and genitourinary tracts. SP-D, a collagenous calcium-dependent lectin (or collectin), binds to surface glycoconjugates expressed by a wide variety of microorganisms, and to oligosaccharides associated with the surface of various complex organic antigens. SP-D also specifically interacts with glycoconjugates and other molecules expressed on the surface of macrophages, neutrophils, and lymphocytes. In addition, SP-D binds to specific surfactant-associated lipids and can influence the organization of lipid mixtures containing phosphatidylinositol in vitro. Consistent with these diverse in vitro activities is the observation that SP-D-deficient transgenic mice show abnormal accumulations of surfactant lipids, and respond abnormally to challenge with respiratory viruses and bacterial lipopolysaccharides. The phenotype of macrophages isolated from the lungs of SP-D-deficient mice is altered, and there is circumstantial evidence that abnormal oxidant metabolism and/or increased metalloproteinase expression contributes to the development of emphysema. The expression of SP-D is increased in response to many forms of lung injury, and deficient accumulation of appropriately oligomerized SP-D might contribute to the pathogenesis of a variety of human lung diseases.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2b73a28n</td>\n",
              "      <td>Role of endothelin-1 in lung diseaseEndothelin-1 (ET-1) is a 21 amino acid peptide with diverse biological activity that has been implicated in numerous diseases. ET-1 is a potent mitogen regulator of smooth muscle tone, and inflammatory mediator that may play a key role in diseases of the airways, pulmonary circulation, and inflammatory lung diseases, both acute and chronic. This review will focus on the biology of ET-1 and its role in lung disease.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9785vg6d</td>\n",
              "      <td>Gene expression in epithelial cells in response to pneumovirus infectionRespiratory syncytial virus (RSV) and pneumonia virus of mice (PVM) are viruses of the family Paramyxoviridae, subfamily pneumovirus, which cause clinically important respiratory infections in humans and rodents, respectively. The respiratory epithelial target cells respond to viral infection with specific alterations in gene expression, including production of chemoattractant cytokines, adhesion molecules, elements that are related to the apoptosis response, and others that remain incompletely understood. Here we review our current understanding of these mucosal responses and discuss several genomic approaches, including differential display reverse transcription-polymerase chain reaction (PCR) and gene array strategies, that will permit us to unravel the nature of these responses in a more complete and systematic manner.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2652324f-ea57-44a7-8cb4-b1a067079969')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2652324f-ea57-44a7-8cb4-b1a067079969 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2652324f-ea57-44a7-8cb4-b1a067079969');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(171325, 2)\n"
          ]
        }
      ],
      "source": [
        "trec_covid_docs_df = pd.read_csv(TREC_COVID_DOCUMENTS_FILE, sep='\\t', header=None, names=['corpus-id', 'corpus-title-text'])\n",
        "\n",
        "display(trec_covid_docs_df.head())\n",
        "\n",
        "print(trec_covid_docs_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_TEXB-7g82S"
      },
      "source": [
        "### Load the TREC COVID queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CtP51ANvg82S",
        "outputId": "31e1d429-de55-4049-f29e-8e1f7fc65c6e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    query-id  \\\n",
              "0          1   \n",
              "1          2   \n",
              "2          3   \n",
              "3          4   \n",
              "4          5   \n",
              "5          6   \n",
              "6          7   \n",
              "7          8   \n",
              "8          9   \n",
              "9         10   \n",
              "10        11   \n",
              "11        12   \n",
              "12        13   \n",
              "13        14   \n",
              "14        15   \n",
              "15        16   \n",
              "16        17   \n",
              "17        18   \n",
              "18        19   \n",
              "19        20   \n",
              "20        21   \n",
              "21        22   \n",
              "22        23   \n",
              "23        24   \n",
              "24        25   \n",
              "25        26   \n",
              "26        27   \n",
              "27        28   \n",
              "28        29   \n",
              "29        30   \n",
              "30        31   \n",
              "31        32   \n",
              "32        33   \n",
              "33        34   \n",
              "34        35   \n",
              "35        36   \n",
              "36        37   \n",
              "37        38   \n",
              "38        39   \n",
              "39        40   \n",
              "40        41   \n",
              "41        42   \n",
              "42        43   \n",
              "43        44   \n",
              "44        45   \n",
              "45        46   \n",
              "46        47   \n",
              "47        48   \n",
              "48        49   \n",
              "49        50   \n",
              "\n",
              "                                                                                                                                                               query-text  \n",
              "0                                                                                                                                          what is the origin of COVID-19  \n",
              "1                                                                                                              how does the coronavirus respond to changes in the weather  \n",
              "2                                                                                          will SARS-CoV2 infected people develop immunity? Is cross protection possible?  \n",
              "3                                                                                                                                        what causes death from Covid-19?  \n",
              "4                                                                                           what drugs have been active against SARS-CoV or SARS-CoV-2 in animal studies?  \n",
              "5                                                                                                           what types of rapid testing for Covid-19 have been developed?  \n",
              "6                                                                                                      are there serological tests that detect antibodies to coronavirus?  \n",
              "7                                                                               how has lack of testing availability led to underreporting of true incidence of Covid-19?  \n",
              "8                                                                                                                                        how has COVID-19 affected Canada  \n",
              "9                                                                                                  has social distancing had an impact on slowing the spread of COVID-19?  \n",
              "10                                                                                               what are the guidelines for triaging patients infected with coronavirus?  \n",
              "11                                                                                            what are best practices in hospitals and at home in maintaining quarantine?  \n",
              "12                                                                                                                       what are the transmission routes of coronavirus?  \n",
              "13                                                                                                             what evidence is there related to COVID-19 super spreaders  \n",
              "14                                                                                                                     how long can the coronavirus live outside the body  \n",
              "15                                                                                                                  how long does coronavirus remain stable  on surfaces?  \n",
              "16                                                                                                            are there any clinical trials available for the coronavirus  \n",
              "17                                                                                                          what are the best masks for preventing infection by Covid-19?  \n",
              "18                                                                                                             what type of hand sanitizer is needed to destroy Covid-19?  \n",
              "19                                                                     are patients taking Angiotensin-converting enzyme inhibitors (ACE) at increased risk for COVID-19?  \n",
              "20                                                                                                       what are the mortality rates overall and in specific populations  \n",
              "21                                                                                                            are cardiac complications likely in patients with COVID-19?  \n",
              "22                                                                                      what kinds of complications related to COVID-19 are associated with hypertension?  \n",
              "23                                                                                           what kinds of complications related to COVID-19 are associated with diabetes  \n",
              "24                                                                                            which biomarkers predict the severe clinical course of 2019-nCOV infection?  \n",
              "25                                                                                                                             what are the initial symptoms of Covid-19?  \n",
              "26                                                                                                 what is known about those infected with Covid-19 but are asymptomatic?  \n",
              "27                                                                                       what evidence is there for the value of hydroxychloroquine in treating Covid-19?  \n",
              "28  which SARS-CoV-2 proteins-human proteins interactions indicate potential for drug targets. Are there approved drugs that can be repurposed based on this information?  \n",
              "29                                                                                                                      is remdesivir an effective treatment for COVID-19  \n",
              "30                                                                                                                     How does the coronavirus differ from seasonal flu?  \n",
              "31                                                                                                            Does SARS-CoV-2 have any subtypes, and if so what are they?  \n",
              "32                                                                                                                 What vaccine candidates are being tested for Covid-19?  \n",
              "33                                                                                             What are the longer-term complications of those who recover from COVID-19?  \n",
              "34                                                                                                            What new public datasets are available related to COVID-19?  \n",
              "35                                                                                                                 What is the protein structure of the SARS-CoV-2 spike?  \n",
              "36                                                                                             What is the result of phylogenetic analysis of SARS-CoV-2 genome sequence?  \n",
              "37                                                                                     What is the mechanism of inflammatory response and pathogenesis of COVID-19 cases?  \n",
              "38                                                                                                      What is the mechanism of cytokine storm syndrome on the COVID-19?  \n",
              "39                                                                         What are the observed mutations in the SARS-CoV-2 genome and how often do the mutations occur?  \n",
              "40                                                             What are the impacts of COVID-19 among African-Americans that differ from the rest of the U.S. population?  \n",
              "41                                                                                                               Does Vitamin D impact COVID-19 prevention and treatment?  \n",
              "42                                                                                  How has the COVID-19 pandemic impacted violence in society, including violent crimes?  \n",
              "43                                                                                                How much impact do masks have on preventing the spread of the COVID-19?  \n",
              "44                                                                                                                  How has the COVID-19 pandemic impacted mental health?  \n",
              "45                                                                                                  what evidence is there for dexamethasone as a treatment for COVID-19?  \n",
              "46                                                                                                       what are the health outcomes for children who contract COVID-19?  \n",
              "47                                                                           what are the benefits and risks of re-opening schools in the midst of the COVID-19 pandemic?  \n",
              "48             do individuals who recover from COVID-19 show sufficient immune response, including antibody levels and T-cell mediated immunity, to prevent re-infection?  \n",
              "49                                                                                                          what is known about an mRNA vaccine for the SARS-CoV-2 virus?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51317472-7688-45cc-9d31-61b6cc56b2e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query-id</th>\n",
              "      <th>query-text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>what is the origin of COVID-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>how does the coronavirus respond to changes in the weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>will SARS-CoV2 infected people develop immunity? Is cross protection possible?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>what causes death from Covid-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>what drugs have been active against SARS-CoV or SARS-CoV-2 in animal studies?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>what types of rapid testing for Covid-19 have been developed?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>are there serological tests that detect antibodies to coronavirus?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>how has lack of testing availability led to underreporting of true incidence of Covid-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>how has COVID-19 affected Canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>has social distancing had an impact on slowing the spread of COVID-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>what are the guidelines for triaging patients infected with coronavirus?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>what are best practices in hospitals and at home in maintaining quarantine?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>what are the transmission routes of coronavirus?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>what evidence is there related to COVID-19 super spreaders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>how long can the coronavirus live outside the body</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>how long does coronavirus remain stable  on surfaces?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>are there any clinical trials available for the coronavirus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>what are the best masks for preventing infection by Covid-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>what type of hand sanitizer is needed to destroy Covid-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>are patients taking Angiotensin-converting enzyme inhibitors (ACE) at increased risk for COVID-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>what are the mortality rates overall and in specific populations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>are cardiac complications likely in patients with COVID-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>what kinds of complications related to COVID-19 are associated with hypertension?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>what kinds of complications related to COVID-19 are associated with diabetes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>which biomarkers predict the severe clinical course of 2019-nCOV infection?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>what are the initial symptoms of Covid-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>what is known about those infected with Covid-19 but are asymptomatic?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>what evidence is there for the value of hydroxychloroquine in treating Covid-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>which SARS-CoV-2 proteins-human proteins interactions indicate potential for drug targets. Are there approved drugs that can be repurposed based on this information?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>is remdesivir an effective treatment for COVID-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "      <td>How does the coronavirus differ from seasonal flu?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>Does SARS-CoV-2 have any subtypes, and if so what are they?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>33</td>\n",
              "      <td>What vaccine candidates are being tested for Covid-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>34</td>\n",
              "      <td>What are the longer-term complications of those who recover from COVID-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>35</td>\n",
              "      <td>What new public datasets are available related to COVID-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>36</td>\n",
              "      <td>What is the protein structure of the SARS-CoV-2 spike?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>37</td>\n",
              "      <td>What is the result of phylogenetic analysis of SARS-CoV-2 genome sequence?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>38</td>\n",
              "      <td>What is the mechanism of inflammatory response and pathogenesis of COVID-19 cases?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>What is the mechanism of cytokine storm syndrome on the COVID-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>40</td>\n",
              "      <td>What are the observed mutations in the SARS-CoV-2 genome and how often do the mutations occur?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>41</td>\n",
              "      <td>What are the impacts of COVID-19 among African-Americans that differ from the rest of the U.S. population?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>42</td>\n",
              "      <td>Does Vitamin D impact COVID-19 prevention and treatment?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>43</td>\n",
              "      <td>How has the COVID-19 pandemic impacted violence in society, including violent crimes?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>44</td>\n",
              "      <td>How much impact do masks have on preventing the spread of the COVID-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>45</td>\n",
              "      <td>How has the COVID-19 pandemic impacted mental health?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>46</td>\n",
              "      <td>what evidence is there for dexamethasone as a treatment for COVID-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>47</td>\n",
              "      <td>what are the health outcomes for children who contract COVID-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>48</td>\n",
              "      <td>what are the benefits and risks of re-opening schools in the midst of the COVID-19 pandemic?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>49</td>\n",
              "      <td>do individuals who recover from COVID-19 show sufficient immune response, including antibody levels and T-cell mediated immunity, to prevent re-infection?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>50</td>\n",
              "      <td>what is known about an mRNA vaccine for the SARS-CoV-2 virus?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51317472-7688-45cc-9d31-61b6cc56b2e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51317472-7688-45cc-9d31-61b6cc56b2e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51317472-7688-45cc-9d31-61b6cc56b2e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trec_covid_queries_df = pd.read_csv(TREC_COVID_QUERIES, sep='\\t', header=None, names=['query-id', 'query-text'])\n",
        "\n",
        "display(trec_covid_queries_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5Ykv9E2g82T"
      },
      "source": [
        "### Now, load the BM25 run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eZGYyCoYg82T"
      },
      "outputs": [],
      "source": [
        "bm25_run_df = pd.read_csv(os.path.join(TREC_COVID_ORIGINAL_RUNS_FOLDER, pyserini_runfile), \n",
        "                          sep=\" \", \n",
        "                          header=None, \n",
        "                          names=['query-id', 'Q0', 'doc-id', 'doc-order', 'doc-score', 'comment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYSPDJyGg82T",
        "outputId": "c40edfc0-75ff-4549-a602-45cc6b3ebc30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "bm25_run_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hwmmwtwKg82T",
        "outputId": "6d2e47ef-64ce-43d7-f3aa-6d9a0b054cbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   query-id  Q0    doc-id  doc-order  doc-score   comment\n",
              "0         1  Q0  dv9m19yk          1   7.729900  Anserini\n",
              "1         1  Q0  hmvo5b0q          2   6.475500  Anserini\n",
              "2         1  Q0  0paafp5j          3   6.431100  Anserini\n",
              "3         1  Q0  96zsd27n          4   6.431099  Anserini\n",
              "4         1  Q0  5d7zien3          5   6.212700  Anserini"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb33ac1c-8328-4eaf-afd3-592b92e10ee6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query-id</th>\n",
              "      <th>Q0</th>\n",
              "      <th>doc-id</th>\n",
              "      <th>doc-order</th>\n",
              "      <th>doc-score</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Q0</td>\n",
              "      <td>dv9m19yk</td>\n",
              "      <td>1</td>\n",
              "      <td>7.729900</td>\n",
              "      <td>Anserini</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Q0</td>\n",
              "      <td>hmvo5b0q</td>\n",
              "      <td>2</td>\n",
              "      <td>6.475500</td>\n",
              "      <td>Anserini</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Q0</td>\n",
              "      <td>0paafp5j</td>\n",
              "      <td>3</td>\n",
              "      <td>6.431100</td>\n",
              "      <td>Anserini</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Q0</td>\n",
              "      <td>96zsd27n</td>\n",
              "      <td>4</td>\n",
              "      <td>6.431099</td>\n",
              "      <td>Anserini</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Q0</td>\n",
              "      <td>5d7zien3</td>\n",
              "      <td>5</td>\n",
              "      <td>6.212700</td>\n",
              "      <td>Anserini</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb33ac1c-8328-4eaf-afd3-592b92e10ee6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb33ac1c-8328-4eaf-afd3-592b92e10ee6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb33ac1c-8328-4eaf-afd3-592b92e10ee6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "bm25_run_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0DziIGZg82U"
      },
      "source": [
        "### Check if hasn't already tokenized the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qztH6Frkg82U"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(TREC_COVID_TOKENIZED_BM25_RUN.format(os.path.splitext(pyserini_runfile)[0])):\n",
        "    with open(TREC_COVID_TOKENIZED_BM25_RUN.format(os.path.splitext(pyserini_runfile)[0]), \"rb\") as inputFile:\n",
        "        \n",
        "        tokenized_data = pickle.load(inputFile)\n",
        "\n",
        "    trec_queries_tokens = tokenized_data['trec_queries_tokens']\n",
        "    trec_docs_tokens = tokenized_data['trec_docs_tokens']\n",
        "    bm25_run_with_all_data_df = tokenized_data['bm25_run_with_all_data_df']\n",
        "    \n",
        "    tokenized_data_read=True\n",
        "else:\n",
        "    tokenized_data_read=False\n",
        "    \n",
        "    print(\"Need to create the tokenized BM25 run data...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GriafRHog82U"
      },
      "source": [
        "### Build the test data to be tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5v1DJfBg82U"
      },
      "source": [
        "#### First, filter the TREC COVID topics text using the corresponding IDs on the run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2bTT_v0g82V",
        "outputId": "d3dfe832-5466-471c-8b42-52f7153f787c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Has already read the tokenized data...\n"
          ]
        }
      ],
      "source": [
        "if not tokenized_data_read:\n",
        "    filtered_topics = trec_covid_queries_df.merge(bm25_run_df, left_on='query-id', right_on='query-id', how='inner')\n",
        "\n",
        "    display(filtered_topics)\n",
        "\n",
        "    bm25_run_with_all_data_df = filtered_topics.merge(trec_covid_docs_df, left_on='doc-id', right_on='corpus-id', how='inner')\n",
        "\n",
        "    display(bm25_run_with_all_data_df)\n",
        "else:\n",
        "    print(\"Has already read the tokenized data...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTecSthxg82V"
      },
      "source": [
        "#### Now, tokenize both topics and returned texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG6XVySTg82V",
        "outputId": "2788fe4a-8639-4301-eafc-894493aa131d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Has already read the tokenized data...\n"
          ]
        }
      ],
      "source": [
        "if not tokenized_data_read:\n",
        "    trec_queries_tokens = tokenizer(bm25_run_with_all_data_df['query-text'].tolist(), \n",
        "                                    truncation=True, \n",
        "                                    max_length=MAX_TOKENS_LENGTH, \n",
        "                                    return_length=True)\n",
        "\n",
        "    print(stats.describe(trec_queries_tokens['length']))\n",
        "\n",
        "    trec_docs_tokens = tokenizer(bm25_run_with_all_data_df['corpus-title-text'].tolist(), \n",
        "                                 truncation=True,\n",
        "                                 return_overflowing_tokens=RETURN_OVERFLOWING_TOKENS, \n",
        "                                 max_length=MAX_TOKENS_LENGTH - np.max(trec_queries_tokens['length']), \n",
        "                                 return_length=True)\n",
        "\n",
        "    print(stats.describe(trec_docs_tokens['length']))\n",
        "    \n",
        "    #### Check if has truncated documents\n",
        "\n",
        "    original_length = bm25_run_with_all_data_df.shape[0]\n",
        "\n",
        "    if 'overflow_to_sample_mapping' in trec_docs_tokens:\n",
        "        if original_length < len(trec_docs_tokens['overflow_to_sample_mapping']):\n",
        "            print(\"Added {} overflowing texts...\".format(len(trec_docs_tokens['overflow_to_sample_mapping']) - original_length))\n",
        "    else:\n",
        "        # Add the field to not break the code\n",
        "\n",
        "        trec_docs_tokens['overflow_to_sample_mapping'] = np.array(list(range(bm25_run_with_all_data_df.shape[0])))\n",
        "\n",
        "\n",
        "    #### Save the tokenized data\n",
        "\n",
        "    with open(TREC_COVID_TOKENIZED_BM25_RUN.format(os.path.splitext(pyserini_runfile)[0]), \"wb\") as outputFile:\n",
        "        pickle.dump({'trec_queries_tokens': trec_queries_tokens,\n",
        "                     'trec_docs_tokens': trec_docs_tokens,\n",
        "                     'bm25_run_with_all_data_df': bm25_run_with_all_data_df}, outputFile, pickle.HIGHEST_PROTOCOL)    \n",
        "else:\n",
        "    print(\"Has already read the tokenized data...\")    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk9ITZAdg82V"
      },
      "source": [
        "### Build the concatenated topic + document to feed the model\n",
        "\n",
        "Remove the 'CLS' token from the documents token sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pn3CSH2Jg82W"
      },
      "outputs": [],
      "source": [
        "test_input_ids = []\n",
        "test_token_type_ids = []\n",
        "test_attention_mask = []\n",
        "\n",
        "# Loop through the documents tokens, since there are overflown ones which shares the same question\n",
        "\n",
        "for i in range(len(trec_docs_tokens['input_ids'])):\n",
        "    \n",
        "    which_query = trec_docs_tokens['overflow_to_sample_mapping'][i]\n",
        "    \n",
        "    test_input_ids.append(trec_queries_tokens['input_ids'][which_query] + trec_docs_tokens['input_ids'][i][1:])\n",
        "    test_token_type_ids.append(trec_queries_tokens['token_type_ids'][which_query] + trec_docs_tokens['token_type_ids'][i][1:])\n",
        "    test_attention_mask.append(trec_queries_tokens['attention_mask'][which_query] + trec_docs_tokens['attention_mask'][i][1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ucLqp6Jvg82W"
      },
      "outputs": [],
      "source": [
        "x_test = {'input_ids': test_input_ids, \n",
        "          'token_type_ids': test_token_type_ids, \n",
        "          'attention_mask': test_attention_mask}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8Tnl58Ng82W"
      },
      "source": [
        "Enter this fixed target data just as reference for the Dataset class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mJayQgByg82W"
      },
      "outputs": [],
      "source": [
        "y_test = np.ones(len(trec_docs_tokens['input_ids']), dtype=bool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLV9R7jKwna1"
      },
      "source": [
        "## Initialize some model structures before doing anything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "T7euXIKeMFxQ"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "\n",
        "    # print(len(batch[0]['input_ids']))\n",
        "\n",
        "    r1 = tokenizer.pad(batch, return_tensors='pt')\n",
        "\n",
        "    # print(len(r1['input_ids'][0]))\n",
        "\n",
        "    return BatchEncoding(r1)\n",
        "\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, examples, targets):\n",
        "        self.examples = examples\n",
        "        self.targets = targets\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.examples['input_ids'])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.examples['input_ids'][idx],\n",
        "            'attention_mask': self.examples['attention_mask'][idx],\n",
        "            'labels': int(self.targets[idx]),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "shk-u70i1NJc"
      },
      "outputs": [],
      "source": [
        "def collect_reranking(model, dataloader, set_name):\n",
        "    losses = []\n",
        "    scores = []\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm.tqdm(dataloader, mininterval=0.5, desc=set_name, disable=False, bar_format='{l_bar}{bar:20}{r_bar}{bar:-20b}', colour='GREEN', file=sys.stdout, position=0, leave=True):\n",
        "            outputs = model(**batch.to(device))\n",
        "            loss_val = outputs.loss\n",
        "            losses.append(loss_val.cpu().item())\n",
        "\n",
        "            scores.append(outputs.logits.cpu())\n",
        "\n",
        "    print(\"{} loss: {:0.4f}\".format(set_name, np.mean(losses)))\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN-qjxweM17D"
      },
      "source": [
        "### Create the dataset and the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "c7-QGvM-0nvB"
      },
      "outputs": [],
      "source": [
        "dataset_test = Dataset(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu0vy1S5hE4M"
      },
      "source": [
        "### Make sure the dataloader preserves the samples order (no shuffling!!!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "MbKdDBf_1CXK"
      },
      "outputs": [],
      "source": [
        "batch_size=300\n",
        "\n",
        "dataloader_test = data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Kk8ZqCD3eWSY"
      },
      "outputs": [],
      "source": [
        "TREC_RESULT_LINE_FORMAT=\"{}\\tQ0\\t{}\\t{}\\t{}\\tInPars_reranking\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8bz0uI8Qg82Y"
      },
      "outputs": [],
      "source": [
        "def consolidate_reranking_scores_and_check_performance(pyserini_runfile, consolidation_approach, bm25_run_with_all_data_df, query_scores):\n",
        "    \n",
        "    consolidated_scores = []\n",
        "\n",
        "    # Consolidate the scores according to the defined approach.\n",
        "    \n",
        "    for i in range(bm25_run_with_all_data_df.shape[0]):\n",
        "        if consolidation_approach == 'mean':\n",
        "            consolidated_scores.append(np.mean(query_scores[i]))\n",
        "        else:\n",
        "            consolidated_scores.append(np.max(query_scores[i]))\n",
        "            \n",
        "    bm25_run_with_all_data_df['reranking_scores'] = consolidated_scores\n",
        "    \n",
        "    test_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    reranked_run = PYSERINI_TEST_RUN_RERANKED_FILENAME_FORMAT.format(os.path.splitext(pyserini_runfile)[0], test_timestamp, consolidation_approach)\n",
        "    \n",
        "    if not os.path.exists(TREC_COVID_RERANKING_RUNS_FOLDER):\n",
        "        os.makedirs(TREC_COVID_RERANKING_RUNS_FOLDER)\n",
        "    \n",
        "    with open(os.path.join(TREC_COVID_RERANKING_RUNS_FOLDER, reranked_run), 'w') as outputFile:\n",
        "        for group_name, group_df in bm25_run_with_all_data_df.groupby('query-id'):\n",
        "            group_df = group_df.sort_values('reranking_scores', ascending=False).reset_index(drop=True)\n",
        "\n",
        "            for i, row in group_df.iterrows():\n",
        "                outputFile.write(TREC_RESULT_LINE_FORMAT.format(group_name, row['doc-id'], i + 1, row['reranking_scores']))\n",
        "                \n",
        "    result = !{TREC_EVAL_FULLPATH} -c -mrecall.1000 -mmap -mndcg_cut.10 -mrecip_rank.100 \\\n",
        "                 {WORKING_FOLDER}/{TREC_COVID_QRELS} {WORKING_FOLDER}/{TREC_COVID_RERANKING_RUNS_FOLDER}/{reranked_run}\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for line in result:\n",
        "\n",
        "        line = line.split('\\t')\n",
        "\n",
        "        results[line[0].strip()] = np.float32(line[-1])    \n",
        "        \n",
        "    return({\"consolidated_scores\": consolidated_scores,\n",
        "            \"reranked_run\": reranked_run,\n",
        "            \"results\": results})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qqiqrMcyg82Y"
      },
      "outputs": [],
      "source": [
        "def rerank_BM25_retrieved_texts(model_checkpoint, dataloader_test, trec_docs_tokens, pyserini_runfile, bm25_run_with_all_data_df):\n",
        "\n",
        "    # Read the model checkpoint\n",
        "    \n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint).to(device)\n",
        "    print('Parameters', model.num_parameters())\n",
        "    \n",
        "    # Rerank the BM25 retrieved documents\n",
        "    \n",
        "    reranking_scores = collect_reranking(model=model, dataloader=dataloader_test, set_name='TREC COVID')\n",
        "    \n",
        "    matches_relevance_score = np.concatenate([batch_scores[:][:, 1].numpy() for batch_scores in reranking_scores])\n",
        "\n",
        "    query_scores = {}\n",
        "\n",
        "    for i, match_score in enumerate(matches_relevance_score):\n",
        "        which_query = trec_docs_tokens['overflow_to_sample_mapping'][i]\n",
        "\n",
        "        if which_query not in query_scores:\n",
        "            query_scores[which_query] = []\n",
        "\n",
        "        query_scores[which_query].append(match_score)\n",
        "        \n",
        "    max_results = consolidate_reranking_scores_and_check_performance(pyserini_runfile, \"max\", bm25_run_with_all_data_df, query_scores)\n",
        "\n",
        "    print(\"\\n\\nMax consolidation results:\")\n",
        "    print(max_results['results'])\n",
        "\n",
        "    mean_results = consolidate_reranking_scores_and_check_performance(pyserini_runfile, \"mean\", bm25_run_with_all_data_df, query_scores)\n",
        "\n",
        "    print(\"\\n\\nMean consolidation results:\")\n",
        "    print(mean_results['results'])\n",
        "    \n",
        "    return reranking_scores, max_results, mean_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvcI99Org82Z"
      },
      "source": [
        "### Execute tests in different pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ym9-FFcg82Z",
        "outputId": "094495fa-17ea-4eb6-9965-8cc222efd516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/435 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 435/435 [13:52<00:00,  1.91s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 1.6150\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1859, 'recip_rank': 0.8343, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5796}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1831, 'recip_rank': 0.8123, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5873}\n"
          ]
        }
      ],
      "source": [
        "MSMARCO_rerank, MSMARCO_max, MSMARCO_mean = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, MS_MARCO_PRETRAINED_MODEL),\n",
        "                                                                        dataloader_test,\n",
        "                                                                        trec_docs_tokens,\n",
        "                                                                        pyserini_runfile, \n",
        "                                                                        bm25_run_with_all_data_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_best_eval, LLM_max_best_eval, LLM_mean_best_eval = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \n",
        "                                                                                                       \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_01_epoch_20230503_005356_eval_0.1699\"),\n",
        "                                                                                          dataloader_test,\n",
        "                                                                                          trec_docs_tokens,\n",
        "                                                                                          pyserini_runfile, \n",
        "                                                                                          bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmqFWvxe6IRP",
        "outputId": "6cfc928b-71f8-475d-df9a-7a048fb56767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:49<00:00,  1.24s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 3.5743\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1842, 'recip_rank': 0.7632, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5376}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1829, 'recip_rank': 0.7196, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5207}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_06, LLM_max_06, LLM_mean_06 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_06_epoch_20230503_012701_0.0426\"),\n",
        "                                                                     dataloader_test,\n",
        "                                                                     trec_docs_tokens,\n",
        "                                                                     pyserini_runfile, \n",
        "                                                                     bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8oAlaoUBfnS",
        "outputId": "99014ab4-1590-4a40-ba36-691dc77c9a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/186 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:50<00:00,  1.24s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 5.5414\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1848, 'recip_rank': 0.7892, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5905}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1848, 'recip_rank': 0.7784, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5854}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_08, LLM_max_08, LLM_mean_08 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_08_epoch_20230503_014021_0.0373\"),\n",
        "                                                                     dataloader_test,\n",
        "                                                                     trec_docs_tokens,\n",
        "                                                                     pyserini_runfile, \n",
        "                                                                     bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiE3dPoae5c3",
        "outputId": "d72e80c7-1c29-447b-af55-ea10817db940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:48<00:00,  1.23s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 5.5695\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1863, 'recip_rank': 0.764, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5509}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1864, 'recip_rank': 0.7478, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5355}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_10, LLM_max_10, LLM_mean_10 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_10_epoch_20230503_015341_0.0295\"),\n",
        "                                                                     dataloader_test,\n",
        "                                                                     trec_docs_tokens,\n",
        "                                                                     pyserini_runfile, \n",
        "                                                                     bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMPYGyxme_su",
        "outputId": "25890070-a1b1-43b3-a6b1-53e64f0d4315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:49<00:00,  1.23s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 5.7646\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1809, 'recip_rank': 0.7432, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5572}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.181, 'recip_rank': 0.7641, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5569}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_13, LLM_max_13, LLM_mean_13 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_13_epoch_20230503_021342_0.0247\"),\n",
        "                                                                     dataloader_test,\n",
        "                                                                     trec_docs_tokens,\n",
        "                                                                     pyserini_runfile, \n",
        "                                                                     bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GxY2o-ze-0t",
        "outputId": "b8deeb7d-447a-4bbe-9a37-9d6bf0c69848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:45<00:00,  1.21s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 6.2144\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1752, 'recip_rank': 0.746, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5152}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1756, 'recip_rank': 0.7455, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5123}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_04, LLM_max_04, LLM_mean_04 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_04_epoch_20230503_011343_0.0489\"),\n",
        "                                                                     dataloader_test,\n",
        "                                                                     trec_docs_tokens,\n",
        "                                                                     pyserini_runfile, \n",
        "                                                                     bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E03_E9MWf_Gc",
        "outputId": "93450944-7a98-4f59-a3fc-b23d6794527c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/186 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:49<00:00,  1.23s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 5.2219\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1853, 'recip_rank': 0.7777, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5499}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.185, 'recip_rank': 0.7503, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5291}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tests without token overflow"
      ],
      "metadata": {
        "id": "FwYsQfXkf_an"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_06_no, LLM_max_06_no, LLM_mean_06_no = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_06_epoch_20230503_012701_0.0426\"),\n",
        "                                                                              dataloader_test,\n",
        "                                                                              trec_docs_tokens,\n",
        "                                                                              pyserini_runfile, \n",
        "                                                                              bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0xRj-V9f_iz",
        "outputId": "69d9c57c-a975-4380-fd57-556d7d86e219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/167 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 167/167 [03:25<00:00,  1.23s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 5.5239\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1863, 'recip_rank': 0.7834, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.589}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1863, 'recip_rank': 0.7834, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.589}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_08_no, LLM_max_08_no, LLM_mean_08_no = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_08_epoch_20230503_014021_0.0373\"),\n",
        "                                                                              dataloader_test,\n",
        "                                                                              trec_docs_tokens,\n",
        "                                                                              pyserini_runfile, \n",
        "                                                                              bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E21e_fMwoOvx",
        "outputId": "ad721a3b-46c3-44a2-b55f-dba5bbfd7120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 167/167 [03:21<00:00,  1.21s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 5.5688\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1877, 'recip_rank': 0.7491, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5468}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1877, 'recip_rank': 0.7491, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5468}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_07_no, LLM_max_07_no, LLM_mean_07_no = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_07_epoch_20230503_013342_0.0419\"),\n",
        "                                                                              dataloader_test,\n",
        "                                                                              trec_docs_tokens,\n",
        "                                                                              pyserini_runfile, \n",
        "                                                                              bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrCGfcIhpQ9q",
        "outputId": "1ae5ecb9-dfb0-4293-cbe7-dfe0fb5f8d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 167/167 [03:21<00:00,  1.21s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 5.2299\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1763, 'recip_rank': 0.6811, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5096}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1763, 'recip_rank': 0.6811, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5096}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSMARCO_rerank_no, MSMARCO_max_no, MSMARCO_mean_no = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, MS_MARCO_PRETRAINED_MODEL),\n",
        "                                                                                 dataloader_test,\n",
        "                                                                                 trec_docs_tokens,\n",
        "                                                                                 pyserini_runfile, \n",
        "                                                                                 bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyZVwEUxp3iB",
        "outputId": "71e15824-c895-4f5e-87a9-c36b9c74ffd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 167/167 [03:21<00:00,  1.20s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 1.4422\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1844, 'recip_rank': 0.826, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5793}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1844, 'recip_rank': 0.826, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5793}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testes no fine-tuning do melhor MS MARCO"
      ],
      "metadata": {
        "id": "N1nI89ansO0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_00_ms, LLM_max_00_ms, LLM_mean_00_ms = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_00_epoch_20230503_175030_0.2501\"),\n",
        "                                                                              dataloader_test,\n",
        "                                                                              trec_docs_tokens,\n",
        "                                                                              pyserini_runfile, \n",
        "                                                                              bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "id": "ETcjHlMBsZOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32db4903-3faa-41e6-928f-11c1fdc2dbd8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/186 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:52<00:00,  1.25s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 2.3788\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.2037, 'recip_rank': 0.7927, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.621}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.2011, 'recip_rank': 0.7787, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6148}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_01_ms, LLM_max_01_ms, LLM_mean_01_ms = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_01_epoch_20230503_175718_0.1441\"),\n",
        "                                                                              dataloader_test,\n",
        "                                                                              trec_docs_tokens,\n",
        "                                                                              pyserini_runfile, \n",
        "                                                                              bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "id": "NTIe0kaTsZFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51dcd80d-2622-4f9e-ac78-c0c6c5cea154"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:51<00:00,  1.24s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 2.7602\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.2009, 'recip_rank': 0.8463, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6042}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.2008, 'recip_rank': 0.7949, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5881}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_02_ms, LLM_max_02_ms, LLM_mean_02_ms = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_02_epoch_20230503_180408_0.1194\"),\n",
        "                                                                              dataloader_test,\n",
        "                                                                              trec_docs_tokens,\n",
        "                                                                              pyserini_runfile, \n",
        "                                                                              bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "id": "s7XXJ6-msY8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83992a6f-88b2-416b-87bf-e7075e5469ed"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:46<00:00,  1.22s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 3.0494\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.198, 'recip_rank': 0.8079, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5837}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1996, 'recip_rank': 0.77, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5775}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_03_ms, LLM_max_03_ms, LLM_mean_03_ms = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_03_epoch_20230503_181056_0.1055\"),\n",
        "                                                                              dataloader_test,\n",
        "                                                                              trec_docs_tokens,\n",
        "                                                                              pyserini_runfile, \n",
        "                                                                              bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "id": "jBp05WlvsYxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d83bbc37-8d3d-46f0-fe99-6c010989191f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:47<00:00,  1.22s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 3.2194\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1975, 'recip_rank': 0.7609, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5679}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1997, 'recip_rank': 0.7554, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5716}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Teste de fine tuning no MS MARCO com Learning Rate menor ― 1e-8"
      ],
      "metadata": {
        "id": "i3wh23RaTff_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_00_ms_lr_1, LLM_max_00_ms_lr_1, LLM_mean_00_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_00_epoch_20230503_204234_0.4395\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwsc25Y7Tfoo",
        "outputId": "09d5b2d3-23db-4741-bee5-df5b6baa15f8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:45<00:00,  1.21s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 1.6707\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1872, 'recip_rank': 0.8253, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5879}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1844, 'recip_rank': 0.8133, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5927}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_01_ms_lr_1, LLM_max_01_ms_lr_1, LLM_mean_01_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_01_epoch_20230503_204914_0.4281\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlh5lNuRTfxH",
        "outputId": "40f44753-92dc-4827-af5b-9a03eed3ea1a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/186 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:52<00:00,  1.25s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 1.7174\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1882, 'recip_rank': 0.838, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5903}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1854, 'recip_rank': 0.8263, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5988}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_01_ms_lr_2, LLM_max_01_ms_lr_2, LLM_mean_01_ms_lr_2 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_02_epoch_20230503_205547_0.4163\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7jwiqXgTf4m",
        "outputId": "79eaf37f-8701-49f2-a18c-412f417b0943"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:45<00:00,  1.21s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 1.7605\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1891, 'recip_rank': 0.8413, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.595}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1863, 'recip_rank': 0.8297, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.605}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_01_ms_lr_3, LLM_max_01_ms_lr_3, LLM_mean_01_ms_lr_3 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_03_epoch_20230503_210220_0.3915\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "id": "_668JCKssYn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6409f11d-446d-482f-9bd2-1052cb7b08b7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:47<00:00,  1.22s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 1.7971\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.19, 'recip_rank': 0.8415, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5968}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1871, 'recip_rank': 0.8299, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6094}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_04_ms_lr_1, LLM_max_04_ms_lr_1, LLM_mean_04_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_04_epoch_20230503_210854_0.3876\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C3xNHCAas6F",
        "outputId": "34597b5d-dd6e-4da6-eeef-dee49cdffe09"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:47<00:00,  1.22s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 1.8296\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1907, 'recip_rank': 0.8415, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5976}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1879, 'recip_rank': 0.8299, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6091}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_05_ms_lr_1, LLM_max_05_ms_lr_1, LLM_mean_05_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_05_epochs_20230503_210958_0.3876\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7aGOtFOcuDL",
        "outputId": "62d34fc3-a578-4b93-931e-762db5b12802"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/186 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:51<00:00,  1.25s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 1.8296\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1907, 'recip_rank': 0.8415, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5976}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1879, 'recip_rank': 0.8299, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6091}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_06_ms_lr_1, LLM_max_06_ms_lr_1, LLM_mean_06_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_00_epoch_20230503_211705_0.3742\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3gcy-TCcuWS",
        "outputId": "119f4602-2fc6-4c5c-c8d9-b32dd1f5961e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:47<00:00,  1.22s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 1.8541\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1915, 'recip_rank': 0.8547, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5995}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1886, 'recip_rank': 0.8429, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6113}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_07_ms_lr_1, LLM_max_07_ms_lr_1, LLM_mean_07_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_01_epoch_20230503_212335_0.3734\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96Xo0h-Se00F",
        "outputId": "788fa426-39bf-4e3a-8512-5d695f036d84"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:46<00:00,  1.22s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 1.8813\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1923, 'recip_rank': 0.8575, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6032}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1893, 'recip_rank': 0.8479, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6155}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_09_ms_lr_1, LLM_max_09_ms_lr_1, LLM_mean_09_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_04_epoch_20230503_214306_0.3554\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNMpgAyowCKv",
        "outputId": "1f07ae43-eca6-47e9-cd04-2b517367fc8c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:45<00:00,  1.21s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 1.9405\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1941, 'recip_rank': 0.8542, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6143}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1912, 'recip_rank': 0.8645, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6207}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_10_ms_lr_1, LLM_max_10_ms_lr_1, LLM_mean_10_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_00_epoch_20230503_224127_0.3430\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "EVS1_94AwBdw",
        "outputId": "5f5a9a2a-f2bc-4686-ec24-3130e2fb6659"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:  80%|\u001b[32m████████████████    \u001b[0m| 149/186 [03:01<00:45,  1.22s/it]\u001b[32m\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-d8e6baf8c1dc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m LLM_rerank_10_ms_lr_1, LLM_max_10_ms_lr_1, LLM_mean_10_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_00_epoch_20230503_224127_0.3430\"),\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                                              \u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                                                              \u001b[0mtrec_docs_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                                              \u001b[0mpyserini_runfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                                              bm25_run_with_all_data_df)\n",
            "\u001b[0;32m<ipython-input-38-99e3963e6198>\u001b[0m in \u001b[0;36mrerank_BM25_retrieved_texts\u001b[0;34m(model_checkpoint, dataloader_test, trec_docs_tokens, pyserini_runfile, bm25_run_with_all_data_df)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Rerank the BM25 retrieved documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mreranking_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_reranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TREC COVID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmatches_relevance_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_scores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreranking_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-30ce3cb21417>\u001b[0m in \u001b[0;36mcollect_reranking\u001b[0;34m(model, dataloader, set_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmininterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{l_bar}{bar:20}{r_bar}{bar:-20b}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolour\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GREEN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1562\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1563\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.45 GiB (GPU 0; 15.77 GiB total capacity; 9.64 GiB already allocated; 3.06 GiB free; 11.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_21_ms_lr_1, LLM_max_21_ms_lr_1, LLM_mean_21_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_06_epoch_20230503_235426_0.2963\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFeoc7kNe0cf",
        "outputId": "0ad3e0c5-aba1-43da-e3b8-2321ad92860d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/186 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [03:50<00:00,  1.24s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 2.0639\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1996, 'recip_rank': 0.8695, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6256}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.196, 'recip_rank': 0.8723, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6262}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_23_ms_lr_1, LLM_max_23_ms_lr_1, LLM_mean_23_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_08_epoch_20230504_000728_0.2839\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "wFtgpxSWe0CP",
        "outputId": "a2df317b-258a-41b3-c20a-94a51ddf7e74"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   6%|\u001b[32m█▎                  \u001b[0m| 12/186 [00:14<03:26,  1.19s/it]\u001b[32m\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-2ccbd276fe8a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m LLM_rerank_23_ms_lr_1, LLM_max_23_ms_lr_1, LLM_mean_23_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_08_epoch_20230504_000728_0.2839\"),\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                                              \u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                                                              \u001b[0mtrec_docs_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                                              \u001b[0mpyserini_runfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                                              bm25_run_with_all_data_df)\n",
            "\u001b[0;32m<ipython-input-38-99e3963e6198>\u001b[0m in \u001b[0;36mrerank_BM25_retrieved_texts\u001b[0;34m(model_checkpoint, dataloader_test, trec_docs_tokens, pyserini_runfile, bm25_run_with_all_data_df)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Rerank the BM25 retrieved documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mreranking_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_reranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TREC COVID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmatches_relevance_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_scores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreranking_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-30ce3cb21417>\u001b[0m in \u001b[0;36mcollect_reranking\u001b[0;34m(model, dataloader, set_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmininterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{l_bar}{bar:20}{r_bar}{bar:-20b}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolour\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GREEN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1562\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1563\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.39 GiB (GPU 0; 15.77 GiB total capacity; 9.73 GiB already allocated; 3.07 GiB free; 11.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_32_ms_lr_1, LLM_max_32_ms_lr_1, LLM_mean_32_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_05_epoch_20230504_004406_0.2626\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3t6scSHF8nb",
        "outputId": "727ff7e4-f52e-43f7-ede5-ff7a103e6721"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/186 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [02:38<00:00,  1.17it/s]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 2.1194\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.2016, 'recip_rank': 0.8662, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6306}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.198, 'recip_rank': 0.874, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6338}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_37_ms_lr_1, LLM_max_37_ms_lr_1, LLM_mean_37_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_10_epoch_20230504_005543_0.2475\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhgfWzPcF8es",
        "outputId": "74cc6599-bdac-48b1-ac0b-c6e93647fd64"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [02:35<00:00,  1.19it/s]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 2.1518\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.2025, 'recip_rank': 0.871, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6296}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1989, 'recip_rank': 0.8663, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6354}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_50_ms_lr_1, LLM_max_50_ms_lr_1, LLM_mean_50_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_23_epoch_20230504_012557_0.2231\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5weA9njWF8XL",
        "outputId": "b3ec494c-4d2c-44db-925d-cb7d375e4894"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/186 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [02:38<00:00,  1.17it/s]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 2.2356\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.2036, 'recip_rank': 0.8304, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6266}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.2001, 'recip_rank': 0.8374, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6273}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_42_ms_lr_1, LLM_max_42_ms_lr_1, LLM_mean_42_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_15_epoch_20230504_010721_0.2386\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mluNaKNF8Pt",
        "outputId": "8125cc8a-4fdd-4741-e53b-777da6490af0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [02:35<00:00,  1.19it/s]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 2.1847\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.2031, 'recip_rank': 0.8503, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6365}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1995, 'recip_rank': 0.8557, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6381}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_47_ms_lr_1, LLM_max_47_ms_lr_1, LLM_mean_47_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_20_epoch_20230504_011900_0.2287\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cO9AeLMF8IN",
        "outputId": "07623edc-5654-4db6-c1d5-7fefa80ebb81"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [02:36<00:00,  1.19it/s]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 2.2162\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.2035, 'recip_rank': 0.8392, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6292}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1999, 'recip_rank': 0.8445, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6297}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_rerank_43_ms_lr_1, LLM_max_43_ms_lr_1, LLM_mean_43_ms_lr_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_16_epoch_20230504_010941_0.2360\"),\n",
        "                                                                                             dataloader_test,\n",
        "                                                                                             trec_docs_tokens,\n",
        "                                                                                             pyserini_runfile, \n",
        "                                                                                             bm25_run_with_all_data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svamEkCkF8As",
        "outputId": "7d6016aa-053d-4f52-df96-10cf1d37a998"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 186/186 [02:35<00:00,  1.19it/s]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 2.1927\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.2032, 'recip_rank': 0.8397, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6359}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1995, 'recip_rank': 0.845, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.6356}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTCiy_l1F74m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lzooLK5F7lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PKwP_CZef_xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E5Jf_wflf_4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other reranking using fine-tune over a MS MARCO partial fine-tune"
      ],
      "metadata": {
        "id": "V5OtDQzYgABK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOPQeIk_g82Z",
        "outputId": "1673246d-1719-4891-b614-b647c736b954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 435/435 [13:41<00:00,  1.89s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 3.9083\n",
            "Max consolidation results:\n",
            "\n",
            "\n",
            "{'map': 0.1818, 'recip_rank': 0.6947, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.4847}\n",
            "Mean consolidation results:\n",
            "\n",
            "\n",
            "{'map': 0.1819, 'recip_rank': 0.6982, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.4899}\n"
          ]
        }
      ],
      "source": [
        "LLM_rerank, LLM_max, LLM_mean = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_100_queries_expansion_20230501_01.jsonl_10_epochs_20230502_000854_0.1437\"),\n",
        "                                                            dataloader_test,\n",
        "                                                            trec_docs_tokens,\n",
        "                                                            pyserini_runfile, \n",
        "                                                            bm25_run_with_all_data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unb6gTFag82a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xlJ59dWg82a",
        "outputId": "737dac07-03e0-4aa0-8a98-ac72c400ff4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/435 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 435/435 [13:34<00:00,  1.87s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 2.9322\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1974, 'recip_rank': 0.7895, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.587}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1941, 'recip_rank': 0.7757, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5921}\n"
          ]
        }
      ],
      "source": [
        "LLM_rerank, LLM_max, LLM_mean = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_100_queries_expansion_20230501_01.jsonl_02_epochs_20230502_112819_0.2561\"),\n",
        "                                                            dataloader_test,\n",
        "                                                            trec_docs_tokens,\n",
        "                                                            pyserini_runfile, \n",
        "                                                            bm25_run_with_all_data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw15l4p2g82a",
        "outputId": "a4d08220-9b68-4671-e0b1-e3b2c7a0015c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 435/435 [13:58<00:00,  1.93s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 3.1475\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1974, 'recip_rank': 0.8083, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5527}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.196, 'recip_rank': 0.815, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5406}\n"
          ]
        }
      ],
      "source": [
        "LLM_rerank_3, LLM_max_3, LLM_mean_3 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_100_queries_expansion_20230501_01.jsonl_03_epochs_20230502_115502_0.1698\"),\n",
        "                                                                  dataloader_test,\n",
        "                                                                  trec_docs_tokens,\n",
        "                                                                  pyserini_runfile, \n",
        "                                                                  bm25_run_with_all_data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8hpMGAig82a",
        "outputId": "d52eea65-c54b-42b2-e61d-ee1750ec1b54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 435/435 [14:08<00:00,  1.95s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 2.1366\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1766, 'recip_rank': 0.655, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.4468}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1755, 'recip_rank': 0.6622, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.4568}\n"
          ]
        }
      ],
      "source": [
        "LLM_rerank_1, LLM_max_1, LLM_mean_1 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_100_queries_expansion_20230501_01.jsonl_01_epochs_20230502_132029_0.4151\"),\n",
        "                                                                  dataloader_test,\n",
        "                                                                  trec_docs_tokens,\n",
        "                                                                  pyserini_runfile, \n",
        "                                                                  bm25_run_with_all_data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lxbxn_p5g82b",
        "outputId": "1c666371-5f4f-40df-eba8-a9d42c73cbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:   0%|\u001b[32m                    \u001b[0m| 0/435 [00:00<?, ?it/s]\u001b[32m\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 435/435 [23:05<00:00,  3.19s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 3.2673\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1842, 'recip_rank': 0.7851, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5241}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1838, 'recip_rank': 0.7911, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5083}\n"
          ]
        }
      ],
      "source": [
        "LLM_rerank_1k_0, LLM_max_1k_0, LLM_mean_1k_0 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_00_epoch_20230502_182845_eval_0.2185\"),\n",
        "                                                                           dataloader_test,\n",
        "                                                                           trec_docs_tokens,\n",
        "                                                                           pyserini_runfile, \n",
        "                                                                           bm25_run_with_all_data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZxNB_xPg82b",
        "outputId": "3a6578f0-8da5-4e96-fe51-b856c685ca92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 435/435 [15:38<00:00,  2.16s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 5.0743\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1929, 'recip_rank': 0.8333, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5499}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1937, 'recip_rank': 0.7811, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5304}\n"
          ]
        }
      ],
      "source": [
        "LLM_rerank_1k_2, LLM_max_1k_2, LLM_mean_1k_2 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_10_epochs_20230502_192235_0.0774\"),\n",
        "                                                                           dataloader_test,\n",
        "                                                                           trec_docs_tokens,\n",
        "                                                                           pyserini_runfile, \n",
        "                                                                           bm25_run_with_all_data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvb0xCYbg82b",
        "outputId": "082af52c-4788-478b-9912-68698ccc10de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 435/435 [33:31<00:00,  4.62s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 5.5671\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1986, 'recip_rank': 0.8166, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5683}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1997, 'recip_rank': 0.7976, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5525}\n"
          ]
        }
      ],
      "source": [
        "LLM_rerank_1k_3, LLM_max_1k_3, LLM_mean_1k_3 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_03_epoch_20230502_204303_0.0687\"),\n",
        "                                                                           dataloader_test,\n",
        "                                                                           trec_docs_tokens,\n",
        "                                                                           pyserini_runfile, \n",
        "                                                                           bm25_run_with_all_data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ul73uhig82c",
        "outputId": "ef207329-2ae5-4ea2-c5ab-581dec8feb1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 435/435 [26:48<00:00,  3.70s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 6.5316\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1928, 'recip_rank': 0.7842, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.546}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1942, 'recip_rank': 0.7537, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5204}\n"
          ]
        }
      ],
      "source": [
        "LLM_rerank_1k_9, LLM_max_1k_9, LLM_mean_1k_9 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_09_epoch_20230502_212226_0.0258\"),\n",
        "                                                                           dataloader_test,\n",
        "                                                                           trec_docs_tokens,\n",
        "                                                                           pyserini_runfile, \n",
        "                                                                           bm25_run_with_all_data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJzgdw6ug82c",
        "outputId": "202ba389-82c0-4a21-a185-e120ed2ff58c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID: 100%|\u001b[32m████████████████████\u001b[0m| 435/435 [16:00<00:00,  2.21s/it]\u001b[32m\u001b[0m\n",
            "TREC COVID loss: 5.9943\n",
            "\n",
            "\n",
            "Max consolidation results:\n",
            "{'map': 0.1921, 'recip_rank': 0.808, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5451}\n",
            "\n",
            "\n",
            "Mean consolidation results:\n",
            "{'map': 0.1945, 'recip_rank': 0.7715, 'recall_1000': 0.3943, 'ndcg_cut_10': 0.5284}\n"
          ]
        }
      ],
      "source": [
        "LLM_rerank_1k_5, LLM_max_1k_5, LLM_mean_1k_5 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_05_epoch_20230502_205610_0.0484\"),\n",
        "                                                                           dataloader_test,\n",
        "                                                                           trec_docs_tokens,\n",
        "                                                                           pyserini_runfile, \n",
        "                                                                           bm25_run_with_all_data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkMsVsmjg82c",
        "outputId": "57b4521b-1ae6-476a-f3f8-75a5d5b5fb09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters 33360770\n",
            "TREC COVID:  29%|\u001b[32m█████▊              \u001b[0m| 126/435 [04:15<10:25,  2.02s/it]\u001b[32m\u001b[0m\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-27e53c33e649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m LLM_rerank_1k_18, LLM_max_1k_18, LLM_mean_1k_18 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_08_epoch_20230502_222731_0.0133\"),\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                               \u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                                               \u001b[0mtrec_docs_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                               \u001b[0mpyserini_runfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                               bm25_run_with_all_data_df)\n",
            "\u001b[0;32m<ipython-input-35-99e3963e6198>\u001b[0m in \u001b[0;36mrerank_BM25_retrieved_texts\u001b[0;34m(model_checkpoint, dataloader_test, trec_docs_tokens, pyserini_runfile, bm25_run_with_all_data_df)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Rerank the BM25 retrieved documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mreranking_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_reranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TREC COVID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmatches_relevance_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_scores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreranking_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-30ce3cb21417>\u001b[0m in \u001b[0;36mcollect_reranking\u001b[0;34m(model, dataloader, set_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "LLM_rerank_1k_18, LLM_max_1k_18, LLM_mean_1k_18 = rerank_BM25_retrieved_texts(os.path.join(TRAIN_OUTPUT_FOLDER, \"checkpoint_eduseiti_1000_queries_expansion_20230502_02.jsonl_08_epoch_20230502_222731_0.0133\"),\n",
        "                                                                              dataloader_test,\n",
        "                                                                              trec_docs_tokens,\n",
        "                                                                              pyserini_runfile, \n",
        "                                                                              bm25_run_with_all_data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKeA_gVAg82c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c468a65e073244cc861799705b738b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f971d8cc79904430b5c66af40416d730",
              "IPY_MODEL_f4065226ff5f4447928b676724fd8f00",
              "IPY_MODEL_1c356f48b5164fde9df0e892791cd3db"
            ],
            "layout": "IPY_MODEL_afc6022e473b43e19d51e44fc618024d"
          }
        },
        "f971d8cc79904430b5c66af40416d730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d269b3cd8a042269b470857405eecb5",
            "placeholder": "​",
            "style": "IPY_MODEL_66e5e3db36424a4b8a6039e36620a821",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "f4065226ff5f4447928b676724fd8f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d98f568966a4f439fef4caf300032e4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0781deb296049e4b7424ba58588aaff",
            "value": 2
          }
        },
        "1c356f48b5164fde9df0e892791cd3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_918dede8c50d47efb14f42a566447c6b",
            "placeholder": "​",
            "style": "IPY_MODEL_831cc349c4524ec4bbc302a9d1682f7e",
            "value": " 2.00/2.00 [00:00&lt;00:00, 157B/s]"
          }
        },
        "afc6022e473b43e19d51e44fc618024d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d269b3cd8a042269b470857405eecb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e5e3db36424a4b8a6039e36620a821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d98f568966a4f439fef4caf300032e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0781deb296049e4b7424ba58588aaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "918dede8c50d47efb14f42a566447c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "831cc349c4524ec4bbc302a9d1682f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18dc59cbf3cb4407bfd14159638ccc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18333806ded246a3beb097e0701d0224",
              "IPY_MODEL_a76e07c18b0647e3a625b51394abe59e",
              "IPY_MODEL_af89b666792d426da404704803383594"
            ],
            "layout": "IPY_MODEL_3ab2bbdf551b46169ef2a7d5cd818b9b"
          }
        },
        "18333806ded246a3beb097e0701d0224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3a723b2eef44ddcb2e4317b34d19336",
            "placeholder": "​",
            "style": "IPY_MODEL_5422775c30124537a21a613c7fd60364",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "a76e07c18b0647e3a625b51394abe59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_163f031c2ba8488db6b70db259da5c29",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f77238a397804c828c8473a7e0b8b46a",
            "value": 385
          }
        },
        "af89b666792d426da404704803383594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_167ef29b30a84542864ba37251d0f689",
            "placeholder": "​",
            "style": "IPY_MODEL_b8b6d16af6c44a8c9f3f6345b4e85695",
            "value": " 385/385 [00:00&lt;00:00, 35.0kB/s]"
          }
        },
        "3ab2bbdf551b46169ef2a7d5cd818b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3a723b2eef44ddcb2e4317b34d19336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5422775c30124537a21a613c7fd60364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "163f031c2ba8488db6b70db259da5c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77238a397804c828c8473a7e0b8b46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "167ef29b30a84542864ba37251d0f689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b6d16af6c44a8c9f3f6345b4e85695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b61a6bee533c4ddc9c9e386a7425585b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2502364ea1244a6a8866c183bc7053b",
              "IPY_MODEL_81a1bce6781d42c2b7ed8265b0c4199e",
              "IPY_MODEL_24fb48ae14f947f1ab15ff03fccc86ab"
            ],
            "layout": "IPY_MODEL_39b0405462a442b18d72ae0fd3e43398"
          }
        },
        "e2502364ea1244a6a8866c183bc7053b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5afa3904a1404c99b93e380f2d3e515b",
            "placeholder": "​",
            "style": "IPY_MODEL_c077363154164a89aa54a553b3d884a1",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "81a1bce6781d42c2b7ed8265b0c4199e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85cbb9c7592549eebe2bb52842deb786",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e472dfab037d43fdb4b6e7765de7d554",
            "value": 231508
          }
        },
        "24fb48ae14f947f1ab15ff03fccc86ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8c42e43f2334e4c918f8980fd43e27c",
            "placeholder": "​",
            "style": "IPY_MODEL_e434a96a95434b7cbbf870957e4c6a74",
            "value": " 232k/232k [00:00&lt;00:00, 1.70MB/s]"
          }
        },
        "39b0405462a442b18d72ae0fd3e43398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5afa3904a1404c99b93e380f2d3e515b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c077363154164a89aa54a553b3d884a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85cbb9c7592549eebe2bb52842deb786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e472dfab037d43fdb4b6e7765de7d554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8c42e43f2334e4c918f8980fd43e27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e434a96a95434b7cbbf870957e4c6a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95ac93a527e84d4b88d476d43824dacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3b6ce71d1cb4ec6bf5f0c524b60fbdf",
              "IPY_MODEL_3c8dcd786f2043f3baf766bbf19cafd4",
              "IPY_MODEL_733ed6a24f8044e8ac0881dd9e958773"
            ],
            "layout": "IPY_MODEL_73e2b8fb0b104319a33d00afdedfa000"
          }
        },
        "f3b6ce71d1cb4ec6bf5f0c524b60fbdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03ff3b2ca66a44518306ebeb3512d8e4",
            "placeholder": "​",
            "style": "IPY_MODEL_a2920381faad47aaae0b9b22275cf0ef",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "3c8dcd786f2043f3baf766bbf19cafd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6853397bce8b4682976ef1223a6eef87",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2f0cd8f60954acba9f67552598cf5d2",
            "value": 112
          }
        },
        "733ed6a24f8044e8ac0881dd9e958773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_270ea75316e24292a7e705f199d53749",
            "placeholder": "​",
            "style": "IPY_MODEL_d9938702085a45898b9b23dc5a45a39b",
            "value": " 112/112 [00:00&lt;00:00, 8.42kB/s]"
          }
        },
        "73e2b8fb0b104319a33d00afdedfa000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03ff3b2ca66a44518306ebeb3512d8e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2920381faad47aaae0b9b22275cf0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6853397bce8b4682976ef1223a6eef87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2f0cd8f60954acba9f67552598cf5d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "270ea75316e24292a7e705f199d53749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9938702085a45898b9b23dc5a45a39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}